#!/usr/bin/env python3
"""
ğŸŒŒ Aoineco-Verified | Multi-Agent Collective Proprietary Skill
S-DNA: AOI-2026-0213-SDNA-SIG1

Aoineco State-Guardian â€” Save Integrity Checker
Reset ì§í›„ ê¸°ì¡´ ì €ì¥ íŒŒì¼ë“¤ì„ êµì°¨ê²€ì¦í•˜ì—¬ ì‹œê°„ì°¨ ì´ìƒì„ íƒì§€í•˜ê³ ,
ì‚¬ìš©ìì—ê²Œ ë³´ê³  í›„ ê°±ì‹ /ë°±ì—…ì„ ì§„í–‰í•˜ëŠ” ìë™í™” ì—”ì§„.

Flow:
  1. SCAN  â†’ ì£¼ìš” íŒŒì¼ë“¤ì˜ ë‚´ë¶€ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
  2. CROSS â†’ íŒŒì¼ ê°„ ì‹œê°„ì°¨ êµì°¨ê²€ì¦
  3. ALERT â†’ ì´ìƒ ê°ì§€ ì‹œ ì‚¬ìš©ì ë³´ê³ 
  4. BACKUP + OVERWRITE â†’ ìŠ¹ì¸ ì‹œ ë°±ì—… í›„ ìµœì‹ ìœ¼ë¡œ ë®ì–´ì“°ê¸°

Copyright (c) 2026 Aoineco & Co. All rights reserved.
"""

import os
import re
import shutil
import json
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone, timedelta
from pathlib import Path

__sdna__ = {
    "protocol": "aoineco-sdna-v1",
    "id": "AOI-2026-0213-SDNA-SIG1",
    "author_agent": "aoineco-collective",
    "org": "aoineco-co",
    "created": "2026-02-13T11:57:00+09:00",
    "tier": "standard",
    "nexus_compatible": True,
    "classification": "open",
}

KST = timezone(timedelta(hours=9))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Files to monitor for staleness (relative to workspace root)
MONITORED_FILES = {
    "CURRENT_STATE.md": {
        "label": "í˜„ì¬ ìƒíƒœ íŒŒì¼",
        "priority": "critical",
        "max_stale_hours": 4,      # 4ì‹œê°„ ì´ìƒ ë¯¸ê°±ì‹  ì‹œ ê²½ê³ 
    },
    "MEMORY.md": {
        "label": "ì¥ê¸° ê¸°ì–µ íŒŒì¼",
        "priority": "critical",
        "max_stale_hours": 12,
    },
    "memory/SQUAD_DASHBOARD.md": {
        "label": "ìŠ¤ì¿¼ë“œ ëŒ€ì‹œë³´ë“œ",
        "priority": "warning",
        "max_stale_hours": 24,
    },
    "HEARTBEAT.md": {
        "label": "í•˜íŠ¸ë¹„íŠ¸ ì„¤ì •",
        "priority": "info",
        "max_stale_hours": 72,
    },
    "IDENTITY.md": {
        "label": "ì •ì²´ì„± íŒŒì¼",
        "priority": "info",
        "max_stale_hours": 168,   # 1ì£¼ì¼
    },
    "LESSONS_LEARNED.md": {
        "label": "ì˜¤ë‹µ ë…¸íŠ¸",
        "priority": "info",
        "max_stale_hours": 72,
    },
}

# Pairs of files that should have consistent information
CROSS_CHECK_PAIRS = [
    {
        "files": ["CURRENT_STATE.md", "MEMORY.md"],
        "description": "í˜„ì¬ ìƒíƒœ vs ì¥ê¸° ê¸°ì–µ â€” í•µì‹¬ í”„ë¡œì íŠ¸ ì§„í–‰ë„ê°€ ì¼ì¹˜í•´ì•¼ í•¨",
        "max_gap_hours": 6,
    },
    {
        "files": ["CURRENT_STATE.md", "memory/SQUAD_DASHBOARD.md"],
        "description": "í˜„ì¬ ìƒíƒœ vs ìŠ¤ì¿¼ë“œ í˜„í™© â€” ë¯¸ì…˜ ìƒíƒœê°€ ë™ê¸°í™”ë˜ì–´ì•¼ í•¨",
        "max_gap_hours": 12,
    },
]

BACKUP_DIR = ".state_backups"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIMESTAMP EXTRACTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Patterns to extract internal timestamps from file content
TIMESTAMP_PATTERNS = [
    # "2026-02-13 11:53 KST" or "(2026-02-13 11:53 KST)"
    r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2})\s*(?:KST|GMT\+9)',
    # "2026-02-13T11:53:00+09:00" (ISO 8601)
    r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}[+\-]\d{2}:\d{2})',
    # "Last updated: 2026-02-13 11:53"
    r'(?:Last\s+updated|Updated|ê°±ì‹ )[:\s]*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2})',
    # "2026-02-12 22:42 KST" in headers
    r'#.*?(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2})',
]


def extract_internal_timestamp(content: str) -> Optional[datetime]:
    """Extract the most recent timestamp mentioned inside a file."""
    timestamps = []
    
    for pattern in TIMESTAMP_PATTERNS:
        matches = re.findall(pattern, content)
        for m in matches:
            try:
                # Try ISO format first
                if 'T' in m and ('+' in m or '-' in m[1:]):
                    dt = datetime.fromisoformat(m)
                    timestamps.append(dt)
                else:
                    # Try "YYYY-MM-DD HH:MM" format (assume KST)
                    clean = m.strip()
                    dt = datetime.strptime(clean, "%Y-%m-%d %H:%M")
                    dt = dt.replace(tzinfo=KST)
                    timestamps.append(dt)
            except (ValueError, IndexError):
                continue
    
    if timestamps:
        return max(timestamps)  # Return the latest timestamp found
    return None


def get_file_mtime(filepath: str) -> Optional[datetime]:
    """Get file modification time as KST datetime."""
    try:
        mtime = os.path.getmtime(filepath)
        return datetime.fromtimestamp(mtime, tz=KST)
    except OSError:
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FileStatus:
    filepath: str
    label: str
    priority: str
    exists: bool
    file_mtime: Optional[datetime]
    internal_timestamp: Optional[datetime]
    stale_hours: float
    max_stale_hours: float
    is_stale: bool
    issue: Optional[str] = None


@dataclass
class CrossCheckResult:
    files: List[str]
    description: str
    gap_hours: float
    max_gap_hours: float
    is_inconsistent: bool
    detail: str


@dataclass
class IntegrityReport:
    scan_time: str
    total_files: int
    stale_files: int
    missing_files: int
    cross_check_issues: int
    file_statuses: List[FileStatus]
    cross_checks: List[CrossCheckResult]
    recommendations: List[str]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STATE GUARDIAN ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class StateGuardian:
    """
    Scans workspace files after session reset and reports staleness.
    """
    
    def __init__(self, workspace_root: str):
        self.root = Path(workspace_root)
        self.backup_dir = self.root / BACKUP_DIR
        self.now = datetime.now(KST)
    
    def scan(self) -> IntegrityReport:
        """Full integrity scan of all monitored files."""
        file_statuses = []
        stale_count = 0
        missing_count = 0
        
        for relpath, config in MONITORED_FILES.items():
            filepath = self.root / relpath
            
            if not filepath.exists():
                file_statuses.append(FileStatus(
                    filepath=relpath,
                    label=config["label"],
                    priority=config["priority"],
                    exists=False,
                    file_mtime=None,
                    internal_timestamp=None,
                    stale_hours=float('inf'),
                    max_stale_hours=config["max_stale_hours"],
                    is_stale=True,
                    issue="âŒ íŒŒì¼ ì—†ìŒ (MISSING)",
                ))
                missing_count += 1
                continue
            
            content = filepath.read_text(encoding='utf-8', errors='ignore')
            file_mtime = get_file_mtime(str(filepath))
            internal_ts = extract_internal_timestamp(content)
            
            # Use the EARLIER of internal timestamp and mtime for staleness
            # (internal timestamp reflects when data was actually current)
            reference_time = internal_ts or file_mtime
            
            if reference_time:
                stale_hours = (self.now - reference_time).total_seconds() / 3600
            else:
                stale_hours = float('inf')
            
            is_stale = stale_hours > config["max_stale_hours"]
            
            # Detect mtime vs internal timestamp discrepancy
            issue = None
            if internal_ts and file_mtime:
                ts_diff = abs((file_mtime - internal_ts).total_seconds() / 3600)
                if ts_diff > 2:
                    issue = (
                        f"âš ï¸ ë‚´ë¶€ íƒ€ì„ìŠ¤íƒ¬í”„({internal_ts.strftime('%m/%d %H:%M')})ì™€ "
                        f"íŒŒì¼ìˆ˜ì •ì‹œê°„({file_mtime.strftime('%m/%d %H:%M')}) ì°¨ì´: "
                        f"{ts_diff:.1f}ì‹œê°„"
                    )
            
            if is_stale and not issue:
                issue = f"ğŸ”´ {stale_hours:.1f}ì‹œê°„ ë¯¸ê°±ì‹  (í•œë„: {config['max_stale_hours']}h)"
            
            if is_stale:
                stale_count += 1
            
            file_statuses.append(FileStatus(
                filepath=relpath,
                label=config["label"],
                priority=config["priority"],
                exists=True,
                file_mtime=file_mtime,
                internal_timestamp=internal_ts,
                stale_hours=round(stale_hours, 1),
                max_stale_hours=config["max_stale_hours"],
                is_stale=is_stale,
                issue=issue,
            ))
        
        # Cross-check pairs
        cross_results = self._cross_check(file_statuses)
        cross_issues = sum(1 for c in cross_results if c.is_inconsistent)
        
        # Generate recommendations
        recommendations = self._recommend(file_statuses, cross_results)
        
        return IntegrityReport(
            scan_time=self.now.strftime("%Y-%m-%d %H:%M KST"),
            total_files=len(file_statuses),
            stale_files=stale_count,
            missing_files=missing_count,
            cross_check_issues=cross_issues,
            file_statuses=file_statuses,
            cross_checks=cross_results,
            recommendations=recommendations,
        )
    
    def _cross_check(self, statuses: List[FileStatus]) -> List[CrossCheckResult]:
        """Cross-validate pairs of files for timestamp consistency."""
        results = []
        status_map = {s.filepath: s for s in statuses}
        
        for pair in CROSS_CHECK_PAIRS:
            files = pair["files"]
            
            # Get reference timestamps for both files
            timestamps = {}
            for f in files:
                if f in status_map and status_map[f].exists:
                    ts = status_map[f].internal_timestamp or status_map[f].file_mtime
                    if ts:
                        timestamps[f] = ts
            
            if len(timestamps) < 2:
                results.append(CrossCheckResult(
                    files=files,
                    description=pair["description"],
                    gap_hours=0,
                    max_gap_hours=pair["max_gap_hours"],
                    is_inconsistent=False,
                    detail="êµì°¨ê²€ì¦ ë¶ˆê°€ (1ê°œ ì´ìƒ íŒŒì¼ ì—†ìŒ ë˜ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ)",
                ))
                continue
            
            ts_list = list(timestamps.values())
            gap_hours = abs((ts_list[0] - ts_list[1]).total_seconds()) / 3600
            is_bad = gap_hours > pair["max_gap_hours"]
            
            # Find which is newer
            newer = max(timestamps, key=timestamps.get)
            older = min(timestamps, key=timestamps.get)
            
            detail = (
                f"{newer} ({timestamps[newer].strftime('%m/%d %H:%M')}) ê¸°ì¤€ ìµœì‹  | "
                f"{older} ({timestamps[older].strftime('%m/%d %H:%M')}) ê¸°ì¤€ êµ¬ë²„ì „ | "
                f"ì‹œê°„ì°¨: {gap_hours:.1f}h"
            )
            
            results.append(CrossCheckResult(
                files=files,
                description=pair["description"],
                gap_hours=round(gap_hours, 1),
                max_gap_hours=pair["max_gap_hours"],
                is_inconsistent=is_bad,
                detail=detail,
            ))
        
        return results
    
    def _recommend(self, statuses: List[FileStatus],
                   cross: List[CrossCheckResult]) -> List[str]:
        """Generate actionable recommendations."""
        recs = []
        
        stale_critical = [s for s in statuses if s.is_stale and s.priority == "critical"]
        stale_warning = [s for s in statuses if s.is_stale and s.priority == "warning"]
        cross_issues = [c for c in cross if c.is_inconsistent]
        
        if stale_critical:
            names = ", ".join(s.filepath for s in stale_critical)
            recs.append(f"ğŸ”´ CRITICAL: {names} â€” ì¦‰ì‹œ ê°±ì‹  í•„ìš”")
        
        if stale_warning:
            names = ", ".join(s.filepath for s in stale_warning)
            recs.append(f"ğŸŸ¡ WARNING: {names} â€” ê°±ì‹  ê¶Œì¥")
        
        if cross_issues:
            for c in cross_issues:
                recs.append(
                    f"ğŸ”€ SYNC: {' â†” '.join(c.files)} â€” "
                    f"{c.gap_hours}h ì‹œê°„ì°¨ (í•œë„: {c.max_gap_hours}h). "
                    f"ìµœì‹  íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ë™ê¸°í™” í•„ìš”"
                )
        
        if not recs:
            recs.append("âœ… ëª¨ë“  íŒŒì¼ì´ ì •ìƒ ë²”ìœ„ ë‚´. ê°±ì‹  ë¶ˆí•„ìš”.")
        
        return recs
    
    def backup_file(self, relpath: str) -> Optional[str]:
        """Create a timestamped backup of a file before overwriting."""
        src = self.root / relpath
        if not src.exists():
            return None
        
        # Create backup directory
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate backup filename
        ts = self.now.strftime("%Y%m%d_%H%M%S")
        safe_name = relpath.replace("/", "__").replace("\\", "__")
        backup_name = f"{ts}__{safe_name}"
        backup_path = self.backup_dir / backup_name
        
        shutil.copy2(str(src), str(backup_path))
        return str(backup_path)
    
    def backup_and_prepare(self, stale_files: List[str]) -> Dict:
        """Backup all stale files before update."""
        backups = {}
        for f in stale_files:
            backup_path = self.backup_file(f)
            if backup_path:
                backups[f] = backup_path
        
        return {
            "backed_up": len(backups),
            "backup_dir": str(self.backup_dir),
            "files": backups,
            "timestamp": self.now.isoformat(),
        }
    
    def format_report(self, report: IntegrityReport) -> str:
        """Format report as human-readable markdown for Telegram."""
        lines = []
        lines.append("ğŸ” **State Integrity Report**")
        lines.append(f"ğŸ“… ìŠ¤ìº” ì‹œê°: {report.scan_time}")
        lines.append("")
        
        # Summary
        if report.stale_files == 0 and report.cross_check_issues == 0:
            lines.append("âœ… **ì „ì²´ ì •ìƒ** â€” ëª¨ë“  íŒŒì¼ì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
            return "\n".join(lines)
        
        lines.append(f"ğŸ“Š ì „ì²´: {report.total_files}ê°œ | "
                     f"ğŸ”´ ë¯¸ê°±ì‹ : {report.stale_files}ê°œ | "
                     f"ğŸ”€ ì‹œê°„ì°¨: {report.cross_check_issues}ê°œ")
        lines.append("")
        
        # Stale files
        stale = [s for s in report.file_statuses if s.is_stale or s.issue]
        if stale:
            lines.append("**ğŸ“‹ ì´ìƒ ê°ì§€ íŒŒì¼:**")
            for s in stale:
                icon = "ğŸ”´" if s.priority == "critical" else "ğŸŸ¡" if s.priority == "warning" else "â„¹ï¸"
                ts_str = s.internal_timestamp.strftime('%m/%d %H:%M') if s.internal_timestamp else "ì—†ìŒ"
                lines.append(f"  {icon} `{s.filepath}` â€” ë‚´ë¶€ì‹œê°„: {ts_str} ({s.stale_hours}h ê²½ê³¼)")
                if s.issue:
                    lines.append(f"    â””â”€ {s.issue}")
            lines.append("")
        
        # Cross-checks
        issues = [c for c in report.cross_checks if c.is_inconsistent]
        if issues:
            lines.append("**ğŸ”€ êµì°¨ê²€ì¦ ë¶ˆì¼ì¹˜:**")
            for c in issues:
                lines.append(f"  âš ï¸ {c.detail}")
            lines.append("")
        
        # Recommendations
        lines.append("**ğŸ¯ ê¶Œì¥ ì¡°ì¹˜:**")
        for r in report.recommendations:
            lines.append(f"  {r}")
        
        return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTEGRATION: "í˜„ì¬ë¥¼ ì €ì¥" Enhanced Flow
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_with_integrity_check(workspace_root: str) -> Dict:
    """
    Enhanced save flow:
    1. Run integrity check FIRST
    2. Report stale/inconsistent files
    3. Create backups of stale files
    4. Return report for user confirmation
    
    Usage by Aoineco agent:
        result = save_with_integrity_check("/path/to/workspace")
        # Show result['report_text'] to user
        # If user approves, proceed to overwrite stale files
    """
    guardian = StateGuardian(workspace_root)
    report = guardian.scan()
    
    stale_files = [s.filepath for s in report.file_statuses if s.is_stale]
    
    # Auto-backup stale files
    backup_result = {}
    if stale_files:
        backup_result = guardian.backup_and_prepare(stale_files)
    
    return {
        "report": report,
        "report_text": guardian.format_report(report),
        "stale_files": stale_files,
        "backups": backup_result,
        "action_needed": len(stale_files) > 0 or report.cross_check_issues > 0,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Run standalone integrity check."""
    import sys
    
    workspace = sys.argv[1] if len(sys.argv) > 1 else os.environ.get(
        "WORKSPACE", os.path.expanduser("~/.openclaw/workspace")
    )
    
    print("=" * 60)
    print("ğŸ” AOINECO STATE-GUARDIAN â€” Integrity Check")
    print("   Trust, but Verify. Every Session.")
    print("=" * 60)
    
    result = save_with_integrity_check(workspace)
    print(result["report_text"])
    
    if result["backups"]:
        print(f"\nğŸ’¾ ë°±ì—… ì™„ë£Œ: {result['backups']['backed_up']}ê°œ íŒŒì¼")
        print(f"   ìœ„ì¹˜: {result['backups']['backup_dir']}")
        for f, b in result['backups'].get('files', {}).items():
            print(f"   ğŸ“ {f} â†’ {os.path.basename(b)}")
    
    print("\n" + "=" * 60)
    
    return result


if __name__ == "__main__":
    main()
